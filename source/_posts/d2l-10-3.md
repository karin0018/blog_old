---
title: chap10 注意力机制(Transformer)
toc: true
comments: true
math: true
date: 2021-12-26 16:02:47
tags: DeepLearning
categories: 跟李沐学 AI
---



layer norm 是对每个句子的全部字归一，batch norm 是全部句子的第 d 个字归一
