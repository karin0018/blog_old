---
title: chap9 现代循环神经网络(6) seq2seq
toc: true
comments: true
math: true
date: 2021-12-22 15:32:01
tags: DeepLearning
categories: 跟李沐学 AI
---

机器翻译中的输入序列和输出序列都是长度可变的。 为了解决这类问题，我们在 （5）节中设计了一个通用的”编码器－解码器“结构。

 在本节中，我们将使用两个循环神经网络来设计这个结构中的编码器和解码器，并将其应用于机器翻译的 *序列到序列*（sequence to sequence，seq2seq）学习

<!--more-->

- 编码器是一个 RNN，读取输入句子
  - 可以是双向（双向可以 encoder，但不能 decoder，即不能用于预测）
- 解码器使用另外一个 RNN 来输出

## 编码器-解码器细节

- 编码器是没有输出的 RNN

- 编码器最后时间步的隐状态用作解码器的初始隐状态

  

## 训练

- 训练时，解码器使用目标句子作为输入



## 衡量生成序列好坏的 BLEU

对于预测序列中的任意 $n$ 元语法（n-grams），BLEU 的评估都是这个 $n$ 元语法是否出现在标签序列中。

用 $p_n$ 表示 $n$ 元语法的精确度，它是两个数量的比值，第一个是预测序列与标签序列中匹配的 $n$ 元语法的数量，第二个是预测序列中 $n$ 元语法的数量的比率。

详细解释，即给定的标签序列 $A$、$B$、$C$、$D$、$E$、$F$ 和预测序列 $A$、$B$、$B$、$C$、$D$，

我们有 $p_1 = 4/5$、$p_2 = 3/4$、$p_3 = 1/3$ 和 $p_4 = 0$。

另外， $\mathrm{len}_{\text{label}}$ 表示标签序列中的词元数和 $\mathrm{len}_{\text{pred}}$ 表示预测序列中的词元数。

那么，**BLEU 的定义是：**
$$
 \exp\left(\min\left(0, 1 - \frac{\mathrm{len}_{\text{label}}}{\mathrm{len}_{\text{pred}}}\right)\right) \prod_{n=1}^k p_n^{1/2^n},
$$
:eqlabel:`eq_bleu`

其中 $k$ 是用于匹配的最长的 $n$ 元语法。

根据 :eqref:`eq_bleu` 中 BLEU 的定义，当预测序列与标签序列完全相同时，BLEU 为 $1$。此外，由于 $n$ 元语法越长则匹配难度越大，所以 BLEU 为更长的 $n$ 元语法的精确度分配更大的权重。

具体来说，当 $p_n$ 固定时，$p_n^{1/2^n}$ 会随着 $n$ 的增长而增加（原始论文使用 $p_n^{1/n}$）。而且，由于预测的序列越短获得的 $p_n$ 值越高，所以 :eqref:`eq_bleu` 中乘法项之前的系数用于惩罚较短的预测序列。

例如，当 $k=2$ 时，给定标签序列 $A$、$B$、$C$、$D$、$E$、$F$ 和预测序列 $A$、$B$，尽管 $p_1 = p_2 = 1$，惩罚因子 $\exp(1-6/2) \approx 0.14$ 会降低 BLEU。



## 总结

- seq2seq 从一个句子生成另一个句子
- 编码器和解码器都是 RNN
- 将编码器最后时间隐状态来初始解码器隐状态来完成信息传递
- 常用 BLEU 来衡量生成序列的好坏

