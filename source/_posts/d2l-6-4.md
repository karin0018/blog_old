---
title:  chap6 卷积神经网络(4) 多输入多输出通道
toc: true
comments: true
math: true
date: 2021-12-19 16:51:42
tags: DeepLearning
categories: 跟李沐学 AI
---

虽然我们在 第（1）小节中描述了构成每个图像的多个通道和多层卷积层。例如彩色图像具有标准的 RGB 通道来指示红、绿和蓝。

但是到目前为止，我们仅展示了单个输入和单个输出通道的简化例子。这使得我们可以将输入、卷积核和输出看作二维张量。

当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。

例如，每个RGB输入图像具有 $3\times h\times w$ 的形状。我们**将这个大小为 $3$ 的轴称为 *通道*（channel） 维度**。在本节中，我们将更深入地研究具有多输入和多输出通道的卷积核。

<!--more-->

## 多输入通道

- **每个通道都有一个卷积核，结果是所有通道卷积结果的和**

{% asset_img conv-multi-in.svg 两个输入通道的互相关计算。 %}

当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数目的卷积核【n 维卷积核】，以便与输入数据进行互相关运算。

假设输入的通道数为 $c_i$，那么卷积核的输入通道数也需要为 $c_i$ 。如果卷积核的窗口形状是 $k_h\times k_w$，那么当 $c_i=1$ 时，我们可以把卷积核看作形状为 $k_h\times k_w$ 的二维张量。

然而，当 $c_i>1$ 时，我们卷积核的每个输入通道将包含形状为 $k_h\times k_w$ 的张量。将这些张量 $c_i$ 连结在一起可以得到形状为 $c_i\times k_h\times k_w$ 的卷积核。由于输入和卷积核都有 $c_i$ 个通道，我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和（将 $c_i$ 的结果相加）得到二维张量。这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。



## 多输出通道

每一层有多个输出通道是至关重要的。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。

直观地说，我们可以将每个通道看作是对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。



- 无论有多少输入通道，到目前位置我们只用到单输出通道

- 我们可以有【多个三维卷积核】，每个核生成一个输出通道

- 用 $c_i$ 和 $c_o$ 分别表示输入和输出通道的数目，并让 $k_h$ 和 $k_w$ 为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为 $c_i\times k_h\times k_w$ 的卷积核张量，这样卷积核的形状是 $c_o\times c_i\times k_h\times k_w$。在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。

- 每个输出通道可以识别特定模式

- 输入通道核识别并组合输入中的模式

  

## 1x1 卷积层

- $k_h=k_w=1$ 是一个受欢迎的选择。它不识别空间模式【只关注一个元素，不关心元素周边】，只是融合通道。
- 相当于输入形状为 $n_hn_w\times c_i$，权重为 $c_o \times c_i$ 的全连接层。



{% asset_img conv-1x1.svg fig_conv_1x1 %}



上图展示了使用 $1\times 1$ 卷积核与 $3$ 个输入通道和 $2$ 个输出通道的互相关计算。

这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。

我们可以将 $1\times 1$ 卷积层看作是在每个像素位置应用的全连接层，以 $c_i$ 个输入值转换为 $c_o$ 个输出值。

因为这仍然是一个卷积层，所以跨像素的权重是一致的。同时，$1\times 1$ 卷积层需要的权重维度为 $c_o\times c_i$ ，再额外加上一个偏置。



## 总结

- 输出通道数是卷积层的超参数
- 每个输入通道有独立的二维卷积核，所有通道结果相加得到一个输出通道结果
- 每个输出通道有独立的三维卷积核

